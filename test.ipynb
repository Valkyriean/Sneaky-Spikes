{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [data/mnist/frames_number_16_split_by_number] already exists.\n",
      "The directory [data/mnist/frames_number_16_split_by_number] already exists.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_data, test_data = get_dataset(\"mnist\", 16, \"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [data/mnist_1k/frames_number_16_split_by_number] already exists.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NMNIST' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# play_frame((train_data[0][0]),\"123.gif\")\u001b[39;00m\n\u001b[1;32m     10\u001b[0m temp \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NMNIST' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# print(len(train_data[0][0][0][1]))\n",
    "# print()\n",
    "# ma = train_data[0][0][0][1]\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "data = NMNIST('data/mnist_1k', train=True, data_type='frame',\n",
    "                           split_by='number', frames_number=16)\n",
    "import numpy as np\n",
    "from spikingjelly.datasets import play_frame\n",
    "# play_frame((train_data[0][0]),\"123.gif\")\n",
    "temp = data[0][0]\n",
    "print(data.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in range(data.shape[1]):\n",
    "    \n",
    "        if polarity == 0:\n",
    "            data[:, di, :, y_begin:y_end, x_begin:x_end] = 0\n",
    "        elif polarity == 1:\n",
    "            data[:, di, 0, y_begin:y_end, x_begin:x_end] = 0\n",
    "            data[:, di, 1, y_begin:y_end, x_begin:x_end] = 1\n",
    "        elif polarity == 2:\n",
    "            data[:, di, 0, y_begin:y_end, x_begin:x_end] = 1\n",
    "            data[:, di, 1, y_begin:y_end, x_begin:x_end] = 0\n",
    "        else:\n",
    "            data[:, di, :, y_begin:y_end, x_begin:x_end] = 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data Shape: (16, 2, 34, 34)\n",
      "Output Data Shape: (16, 2, 34, 34)\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "def matrix_to_bytes(matrix):\n",
    "    \"\"\"将34x34矩阵展平成字节序列\"\"\"\n",
    "    flattened = matrix.flatten()\n",
    "    return flattened.tobytes()\n",
    "\n",
    "def hash_matrix(matrix):\n",
    "    byte_data = matrix_to_bytes(matrix)\n",
    "    \n",
    "    # 使用SHA-256哈希函数\n",
    "    hash_obj = hashlib.sha256(byte_data)\n",
    "    hash_digest = hash_obj.digest()\n",
    "    \n",
    "    # 如果哈希结果不足需要的长度，重复哈希结果直到长度足够\n",
    "    hash_data = bytearray()\n",
    "    while len(hash_data) < 1156 * 4:  # 1156个整数，每个4字节\n",
    "        hash_data.extend(hash_digest)\n",
    "        hash_obj.update(hash_digest)\n",
    "        hash_digest = hash_obj.digest()\n",
    "    \n",
    "    # 截取所需长度\n",
    "    hash_data = hash_data[:1156 * 4]\n",
    "    \n",
    "    # 将字节序列转换为整数数组\n",
    "    hashed_matrix = np.frombuffer(hash_data, dtype=np.int32).reshape((34, 34)).astype(np.float64)\n",
    "    \n",
    "    # 归一化到0到10的范围内\n",
    "    min_val = np.min(hashed_matrix)\n",
    "    max_val = np.max(hashed_matrix)\n",
    "    \n",
    "    if max_val != min_val:  # 避免除以零\n",
    "        normalized_matrix = 10 * (hashed_matrix - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        normalized_matrix = np.zeros_like(hashed_matrix)\n",
    "    \n",
    "    return np.round(normalized_matrix).astype(int)\n",
    "\n",
    "def process_video_frames(input_data):\n",
    "    # 创建一个相同形状的数组来存储结果\n",
    "    output_data = np.empty_like(input_data, dtype=np.int32)\n",
    "    \n",
    "    for frame_idx in range(input_data.shape[0]):\n",
    "        for color_idx in range(input_data.shape[1]):\n",
    "            original_matrix = input_data[frame_idx, color_idx, :, :]\n",
    "            hashed_matrix = hash_matrix(original_matrix)\n",
    "            output_data[frame_idx, color_idx, :, :] = hashed_matrix\n",
    "    \n",
    "    return output_data\n",
    "\n",
    "# 示例使用\n",
    "input_data = temp\n",
    "output_data = process_video_frames(input_data)\n",
    "\n",
    "print(\"Input Data Shape:\", input_data.shape)\n",
    "print(\"Output Data Shape:\", output_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save frames to [encrypt.gif].\n"
     ]
    }
   ],
   "source": [
    "final_data = output_data*0.01+input_data\n",
    "play_frame(final_data,\"encrypt.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [data/mnist/frames_number_16_split_by_number] already exists.\n",
      "10.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "data = NMNIST('data/mnist', train=True, data_type='frame',\n",
    "                           split_by='number', frames_number=16)\n",
    "\n",
    "# print(np.max(data)\n",
    "data1 = [x for x, y in data]\n",
    "print(np.max(data1))    \n",
    "print(np.min(data1))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
